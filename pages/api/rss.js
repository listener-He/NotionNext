import { getGlobalData } from '@/lib/db/getSiteData'
import { generateRssFeed } from '@/lib/rss'
import { getOrSetDataWithCustomCache } from '@/lib/cache/cache_manager'
import { CACHE_KEY_RSS } from '@/lib/cache/cache_keys'
import { gzip } from 'zlib'
import { promisify } from 'util'

const gzipAsync = promisify(gzip)

// RSSç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰- 30åˆ†é’Ÿ
const RSS_CACHE_TIME = 30 * 60

/**
 * RSS API è·¯ç”±
 * åœ¨ Vercel ç­‰æ— æœåŠ¡å™¨ç¯å¢ƒä¸­åŠ¨æ€ç”Ÿæˆ RSS å†…å®¹
 * å¤ç”¨åŸæœ‰çš„ RSS ç”Ÿæˆé€»è¾‘
 * 
 * åŠŸèƒ½ç‰¹æ€§ï¼š
 * - æ”¯æŒå¤šç§æ ¼å¼ï¼šRSS2.0 (é»˜è®¤)ã€Atomã€JSON Feed
 * - é›†æˆç¼“å­˜ç®¡ç†å™¨ï¼Œ30åˆ†é’Ÿç¼“å­˜æ—¶é—´
 * - æ”¯æŒ gzip å‹ç¼©ï¼Œä¼˜åŒ–ä¼ è¾“æ€§èƒ½
 * - ç‹¬ç«‹ç¼“å­˜ä¸åŒæ ¼å¼çš„RSSå†…å®¹
 * 
 * æŸ¥è¯¢å‚æ•°ï¼š
 * - format: 'rss2' | 'atom' | 'json' (å¯é€‰ï¼Œé»˜è®¤ä¸º rss2)
 * 
 * ç¤ºä¾‹ï¼š
 * - GET /api/rss - è¿”å› RSS2.0 æ ¼å¼
 * - GET /api/rss?format=atom - è¿”å› Atom æ ¼å¼
 * - GET /api/rss?format=json - è¿”å› JSON Feed æ ¼å¼
 */
export default async function handler(req, res) {
  try {
    // æ ¹æ®è¯·æ±‚çš„æ ¼å¼ç¡®å®šç¼“å­˜é”®å’Œå†…å®¹ç±»å‹
    const { format } = req.query
    const cacheKey = CACHE_KEY_RSS(format || 'rss2');
    let contentType
    
    switch (format) {
      case 'atom':
        contentType = 'application/atom+xml; charset=utf-8'
        break
      case 'json':
        contentType = 'application/json; charset=utf-8'
        break
      default:
        contentType = 'application/rss+xml; charset=utf-8'
        break
    }

    // ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨è·å–æˆ–ç”ŸæˆRSSå†…å®¹
    const startTime = Date.now()
    const content = await getOrSetDataWithCustomCache(
      cacheKey,
      RSS_CACHE_TIME,
      async () => {
        console.log(`[RSS API] ğŸ”„ ç”Ÿæˆæ–°çš„RSSå†…å®¹: ${format || 'rss2'}`)
        
        // è·å–ç«™ç‚¹æ•°æ®
        const props = await getGlobalData({ from: 'rss-api' })
        
        if (!props || !props.latestPosts) {
          throw new Error('Failed to fetch site data')
        }

        // ä½¿ç”¨åŸæœ‰çš„ RSS ç”Ÿæˆé€»è¾‘
        const feed = await generateRssFeed(props)
        
        if (!feed) {
          throw new Error('Failed to generate RSS feed')
        }

        // æ ¹æ®æ ¼å¼ç”Ÿæˆå¯¹åº”çš„RSSå†…å®¹
        switch (format) {
          case 'atom':
            return feed.atom1()
          case 'json':
            return feed.json1()
          default:
            return feed.rss2()
        }
      }
    )
    
    const duration = Date.now() - startTime
    console.log(`[RSS API] âš¡ RSSå“åº”å®Œæˆ: ${format || 'rss2'}, è€—æ—¶: ${duration}ms`)
    
    if (!content) {
      return res.status(500).json({ error: 'Failed to generate RSS feed' })
    }

    // æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ”¯æŒ gzip å‹ç¼©
    const acceptEncoding = req.headers['accept-encoding'] || ''
    const shouldCompress = acceptEncoding.includes('gzip') && content.length > 1024

    res.setHeader('Content-Type', contentType)
    
    if (shouldCompress) {
      try {
        const compressed = await gzipAsync(Buffer.from(content, 'utf8'))
        res.setHeader('Content-Encoding', 'gzip')
        res.setHeader('Vary', 'Accept-Encoding')
        res.setHeader('Content-Length', compressed.length)
        return res.status(200).send(compressed)
      } catch (compressionError) {
        console.warn('[RSS API] å‹ç¼©å¤±è´¥ï¼Œè¿”å›æœªå‹ç¼©å†…å®¹:', compressionError)
        // å¦‚æœå‹ç¼©å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
        return res.status(200).send(content)
      }
    } else {
      return res.status(200).send(content)
    }
  } catch (error) {
    console.error('[RSS API] ç”Ÿæˆå¤±è´¥:', error)
    return res.status(500).json({ error: 'Failed to generate RSS feed' })
  }
}