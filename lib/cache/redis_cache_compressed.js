import BLOG from '@/blog.config'
import { siteConfig } from '@/lib/config'
import Redis from 'ioredis'

// zstd-codec åŠ¨æ€å¯¼å…¥å’Œåˆå§‹åŒ–
let zstdCodec = null
let compressionAvailable = false

// åˆå§‹åŒ– zstd-codec
async function initZstdCodec() {
  try {
    const { ZstdCodec } = await import('zstd-codec')
    return new Promise((resolve) => {
      ZstdCodec.run(zstd => {
        zstdCodec = zstd
        compressionAvailable = true
        console.log('âœ… ZSTD compression enabled')
        resolve(zstd)
      })
    })
  } catch (error) {
    console.warn('âš ï¸ ZSTD codec not available:', error.message)
    compressionAvailable = false
    return null
  }
}

// åˆå§‹åŒ– zstd-codec
initZstdCodec()

// å‹ç¼©å‡½æ•°
function compressData(data, level = 3) {
  if (!compressionAvailable || !zstdCodec) {
    throw new Error('ZSTD codec not available')
  }
  
  try {
    const simple = new zstdCodec.Simple()
    return simple.compress(data, level)
  } catch (error) {
    console.error('ZSTD compression error:', error)
    throw error
  }
}

// è§£å‹å‡½æ•°
function decompressData(compressedData) {
  if (!compressionAvailable || !zstdCodec) {
    throw new Error('ZSTD codec not available')
  }
  
  try {
    const simple = new zstdCodec.Simple()
    return simple.decompress(compressedData)
  } catch (error) {
    console.error('ZSTD decompression error:', error)
    throw error
  }
}

// è¿æ¥æ± é…ç½®
const redisClient = new Redis({
  url: BLOG.REDIS_URL,
  connectTimeout: 2000, // è¶…æ—¶æ—¶é—´2ç§’
  maxRetriesPerRequest: 1,
  reconnectOnError: () => true,
  retryStrategy(times) {
    return Math.min(times * 50, 2000)
  },
  connectionName: 'blog-redis-client',
  lazyConnect: true,
  minIdleTime: 60000, // é—²ç½®æ—¶é—´60ç§’
  idleCheckInterval: 15000, // æ¯15ç§’æ£€æŸ¥ä¸€æ¬¡é—²ç½®è¿æ¥
  minConnections: 1,
  maxConnections: 15
})

const cacheTime = Math.trunc(
  siteConfig('NEXT_REVALIDATE_SECOND', BLOG.NEXT_REVALIDATE_SECOND) * 1.5
)

// å‹ç¼©é˜ˆå€¼ï¼šè¶…è¿‡æ­¤å¤§å°çš„æ•°æ®æ‰è¿›è¡Œå‹ç¼©ï¼ˆå­—èŠ‚ï¼‰
const COMPRESSION_THRESHOLD = 1 * 1024 // 1KB

// åŠ¨æ€å‹ç¼©çº§åˆ«é…ç½®ï¼šæ ¹æ®æ•°æ®å¤§å°æ™ºèƒ½è°ƒæ•´å‹ç¼©çº§åˆ«
const COMPRESSION_LEVELS = {
  small: 1,    // 1KB-5KB: é€Ÿåº¦ä¼˜å…ˆ
  medium: 6,   // 5KB-50KB: å¹³è¡¡æ€§èƒ½
  large: 15,   // 50KB-100KB: è¾ƒé«˜å‹ç¼©çº§åˆ«
  highest: 22  // >100KB: æœ€é«˜å‹ç¼©çº§åˆ«
}
const SIZE_THRESHOLDS = {
  small: 5 * 1024,    // 5KB
  medium: 50 * 1024,  // 50KB
  large: 100 * 1024   // 100KB
}

const MIN_COMPRESSION_RATIO = 0.15 // æœ€å°å‹ç¼©æ•ˆæœé˜ˆå€¼ (15%èŠ‚çœç©ºé—´æ‰ä½¿ç”¨å‹ç¼©)

/**
 * æ ¹æ®æ•°æ®å¤§å°åŠ¨æ€é€‰æ‹©å‹ç¼©çº§åˆ«
 * @param {number} dataSize - æ•°æ®å¤§å°ï¼ˆå­—èŠ‚ï¼‰
 * @returns {number} å‹ç¼©çº§åˆ«
 */
function getDynamicCompressionLevel(dataSize) {
  if (dataSize <= SIZE_THRESHOLDS.small) return COMPRESSION_LEVELS.small
  if (dataSize <= SIZE_THRESHOLDS.medium) return COMPRESSION_LEVELS.medium
  if (dataSize <= SIZE_THRESHOLDS.large) return COMPRESSION_LEVELS.large
  return COMPRESSION_LEVELS.highest
}

/**
 * ä»ç¼“å­˜ä¸­è·å–æ•°æ®
 */
export async function getCache(key) {
  try {
    const value = await redisClient.get(key)
    if (!value) return null

    // æ£€æŸ¥æ˜¯å¦ä¸ºå‹ç¼©æ•°æ®
    if (value.startsWith('ZSTD:')) {
      if (!compressionAvailable) {
        console.warn('âš ï¸ Found compressed data but ZSTD codec not available')
        return null
      }
      
      const compressedData = Buffer.from(value.slice(5), 'base64')
      const decompressed = decompressData(new Uint8Array(compressedData))
      return JSON.parse(Buffer.from(decompressed).toString('utf8'))
    }

    return JSON.parse(value)
  } catch (error) {
    console.error('Cache get error:', error)
    return null
  }
}

/**
 * è®¾ç½®ç¼“å­˜æ•°æ®
 */
export async function setCache(key, data, customCacheTime) {
  try {
    const jsonString = JSON.stringify(data)
    const dataBuffer = Buffer.from(jsonString, 'utf8')
    const dataSize = dataBuffer.length
    let finalValue = jsonString
    let compressionStats = null

    // æ™ºèƒ½å‹ç¼©ç­–ç•¥ï¼šä»…å¯¹å¤§äºé˜ˆå€¼çš„æ•°æ®è¿›è¡Œå‹ç¼©
    if (compressionAvailable && dataSize > COMPRESSION_THRESHOLD) {
      const compressionLevel = getDynamicCompressionLevel(dataSize)
      const startTime = Date.now()
      
      try {
        const compressed = compressData(new Uint8Array(dataBuffer), compressionLevel)
        const compressedSize = compressed.length
        const compressionTime = Date.now() - startTime
        const compressionRatio = (dataSize - compressedSize) / dataSize
        
        compressionStats = {
          originalSize: dataSize,
          compressedSize,
          compressionRatio,
          compressionTime,
          level: compressionLevel
        }
        
        // ä»…åœ¨å‹ç¼©æ•ˆæœæ˜¾è‘—æ—¶ä½¿ç”¨å‹ç¼©ï¼ˆèŠ‚çœç©ºé—´â‰¥15%ï¼‰
        if (compressionRatio >= MIN_COMPRESSION_RATIO) {
          finalValue = 'ZSTD:' + Buffer.from(compressed).toString('base64')
          console.log(`ğŸ—œï¸ Cache compressed: ${(dataSize/1024).toFixed(1)}KB â†’ ${(compressedSize/1024).toFixed(1)}KB (${(compressionRatio*100).toFixed(1)}% saved, level ${compressionLevel}, ${compressionTime}ms)`)
        } else {
          console.log(`ğŸ“¦ Cache not compressed: ratio ${(compressionRatio*100).toFixed(1)}% < ${(MIN_COMPRESSION_RATIO*100)}% threshold`)
        }
      } catch (compressionError) {
        console.warn('âš ï¸ Compression failed, storing uncompressed:', compressionError.message)
      }
    } else if (!compressionAvailable && dataSize > COMPRESSION_THRESHOLD) {
      console.log('ğŸ“¦ Large data detected but ZSTD codec not available, storing uncompressed')
    }

    const ttl = customCacheTime || cacheTime
    await redisClient.setex(key, ttl, finalValue)
    
    return compressionStats
  } catch (error) {
    console.error('Cache set error:', error)
    throw error
  }
}

/**
 * åˆ é™¤ç¼“å­˜
 */
export async function delCache(key) {
  try {
    return await redisClient.del(key)
  } catch (error) {
    console.error('Cache delete error:', error)
    return 0
  }
}

/**
 * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
 */
export async function getCacheStats(keyPattern = '*') {
  try {
    const keys = await redisClient.keys(keyPattern)
    if (keys.length === 0) {
      return { totalKeys: 0, totalSize: 0, compressedKeys: 0, uncompressedKeys: 0 }
    }

    // é‡‡æ ·å‰100ä¸ªé”®è¿›è¡Œç»Ÿè®¡
    const sampleKeys = keys.slice(0, 100)
    const values = await redisClient.mget(sampleKeys)
    
    let totalSize = 0
    let compressedKeys = 0
    let uncompressedKeys = 0
    
    values.forEach(value => {
      if (value) {
        totalSize += Buffer.byteLength(value, 'utf8')
        if (value.startsWith('ZSTD:')) {
          compressedKeys++
        } else {
          uncompressedKeys++
        }
      }
    })
    
    return {
      totalKeys: keys.length,
      sampledKeys: sampleKeys.length,
      totalSize: Math.round(totalSize / 1024), // KB
      compressedKeys,
      uncompressedKeys,
      compressionRatio: compressedKeys / (compressedKeys + uncompressedKeys)
    }
  } catch (error) {
    console.error('Cache stats error:', error)
    return { error: error.message }
  }
}

export default { getCache, setCache, delCache, getCacheStats }