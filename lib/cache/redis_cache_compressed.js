import BLOG from '@/blog.config'
import { siteConfig } from '@/lib/config'
import Redis from 'ioredis'

// zstd-codec åŠ¨æ€å¯¼å…¥å’Œåˆå§‹åŒ–
let zstdCodec = null
let compressionAvailable = false

// åˆå§‹åŒ– zstd-codec
async function initZstdCodec() {
  try {
    const { ZstdCodec } = await import('zstd-codec')
    return new Promise((resolve) => {
      ZstdCodec.run(zstd => {
        zstdCodec = zstd
        compressionAvailable = true
        console.log('âœ… ZSTD compression enabled')
        resolve(zstd)
      })
    })
  } catch (error) {
    console.warn('âš ï¸ ZSTD codec not available:', error.message)
    compressionAvailable = false
    return null
  }
}

// åˆå§‹åŒ– zstd-codec
initZstdCodec()

// å‹ç¼©å‡½æ•°
function compressData(data, level = 3) {
  if (!compressionAvailable || !zstdCodec) {
    throw new Error('ZSTD codec not available')
  }
  
  // éªŒè¯è¾“å…¥æ•°æ®
  if (!data || data.length === 0) {
    return new Uint8Array(0) // è¿”å›ç©ºçš„ Uint8Array
  }
  
  // æ£€æŸ¥æ•°æ®å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
  if (data.length > 100 * 1024 * 1024) { // 100MB é™åˆ¶
    throw new Error('Data too large for compression: ' + data.length + ' bytes')
  }
  
  try {
    const simple = new zstdCodec.Simple()
    return simple.compress(data, level)
  } catch (error) {
    console.error('ZSTD compression error:', error)
    throw error
  }
}

// è§£å‹å‡½æ•°
function decompressData(compressedData) {
  if (!compressionAvailable || !zstdCodec) {
    throw new Error('ZSTD codec not available')
  }
  
  try {
    const simple = new zstdCodec.Simple()
    return simple.decompress(compressedData)
  } catch (error) {
    console.error('ZSTD decompression error:', error)
    throw error
  }
}

// è¿æ¥æ± é…ç½®
// è§£æ Redis URL æˆ–ä½¿ç”¨é»˜è®¤é…ç½®
let redisConfig = {}
if (BLOG.REDIS_URL) {
  try {
    const url = new URL(BLOG.REDIS_URL)
    redisConfig = {
      host: url.hostname,
      port: parseInt(url.port) || 6379,
      username: url.username || undefined,
      password: url.password || undefined,
      db: url.pathname && url.pathname.length > 1 ? parseInt(url.pathname.slice(1)) : 0
    }
    console.log('âœ… Redis URL parsed successfully:', `${url.hostname}:${url.port}`)
  } catch (error) {
    console.warn('âš ï¸ Invalid Redis URL, using default config:', error.message)
    redisConfig = { host: '127.0.0.1', port: 6379 }
  }
} else {
  redisConfig = { host: '127.0.0.1', port: 6379 }
}

const redisClient = new Redis({
  ...redisConfig,
  connectTimeout: 2000, // è¶…æ—¶æ—¶é—´2ç§’
  maxRetriesPerRequest: 1,
  reconnectOnError: () => true,
  retryStrategy(times) {
    return Math.min(times * 50, 2000)
  },
  connectionName: 'blog-redis-client',
  lazyConnect: true,
  minIdleTime: 60000, // é—²ç½®æ—¶é—´60ç§’
  idleCheckInterval: 15000, // æ¯15ç§’æ£€æŸ¥ä¸€æ¬¡é—²ç½®è¿æ¥
  minConnections: 1,
  maxConnections: 15
})

const cacheTime = Math.trunc(
  siteConfig('NEXT_REVALIDATE_SECOND', BLOG.NEXT_REVALIDATE_SECOND) * 1.5
)

// å‹ç¼©é˜ˆå€¼ï¼šè¶…è¿‡æ­¤å¤§å°çš„æ•°æ®æ‰è¿›è¡Œå‹ç¼©ï¼ˆå­—èŠ‚ï¼‰
const COMPRESSION_THRESHOLD = 1 * 1024 // 1KB

// åŠ¨æ€å‹ç¼©çº§åˆ«é…ç½®ï¼šæ ¹æ®æ•°æ®å¤§å°æ™ºèƒ½è°ƒæ•´å‹ç¼©çº§åˆ«ï¼ˆ6ä¸ªçº§åˆ«ï¼‰
const COMPRESSION_LEVELS = {
  level1: 3,    // 1KB-10KB: æœ€ä½çº§åˆ«ï¼Œé€Ÿåº¦ä¼˜å…ˆ
  level2: 6,    // 10KB-50KB: ä½çº§åˆ«ï¼Œå¹³è¡¡æ€§èƒ½
  level3: 9,    // 50KB-100KB: ä¸­ç­‰çº§åˆ«
  level4: 12,   // 100KB-200KB: ä¸­é«˜çº§åˆ«
  level5: 15,   // 200KB-500KB: é«˜çº§åˆ«
  level6: 22    // >500KB: æœ€é«˜çº§åˆ«ï¼Œå‹ç¼©ç‡ä¼˜å…ˆ
}
const SIZE_THRESHOLDS = {
  level1: 10 * 1024,   // 10KB
  level2: 50 * 1024,   // 50KB
  level3: 100 * 1024,  // 100KB
  level4: 200 * 1024,  // 200KB
  level5: 500 * 1024   // 500KB
}

const MIN_COMPRESSION_RATIO = 0.15 // æœ€å°å‹ç¼©æ•ˆæœé˜ˆå€¼ (15%èŠ‚çœç©ºé—´æ‰ä½¿ç”¨å‹ç¼©)

/**
 * æ ¹æ®æ•°æ®å¤§å°åŠ¨æ€é€‰æ‹©å‹ç¼©çº§åˆ«
 * @param {number} dataSize - æ•°æ®å¤§å°ï¼ˆå­—èŠ‚ï¼‰
 * @returns {number} å‹ç¼©çº§åˆ«
 */
function getDynamicCompressionLevel(dataSize) {
  if (dataSize <= SIZE_THRESHOLDS.level1) return COMPRESSION_LEVELS.level1
  if (dataSize <= SIZE_THRESHOLDS.level2) return COMPRESSION_LEVELS.level2
  if (dataSize <= SIZE_THRESHOLDS.level3) return COMPRESSION_LEVELS.level3
  if (dataSize <= SIZE_THRESHOLDS.level4) return COMPRESSION_LEVELS.level4
  if (dataSize <= SIZE_THRESHOLDS.level5) return COMPRESSION_LEVELS.level5
  return COMPRESSION_LEVELS.level6
}

/**
 * ä»ç¼“å­˜ä¸­è·å–æ•°æ®
 */
export async function getCache(key) {
  try {
    const value = await redisClient.get(key)
    if (!value) return null

    // æ£€æŸ¥æ˜¯å¦ä¸ºå‹ç¼©æ•°æ®
    if (value.startsWith('ZSTD:')) {
      if (!compressionAvailable) {
        console.warn('âš ï¸ Found compressed data but ZSTD codec not available')
        return null
      }
      
      const compressedData = Buffer.from(value.slice(5), 'base64')
      const decompressed = decompressData(new Uint8Array(compressedData))
      return JSON.parse(Buffer.from(decompressed).toString('utf8'))
    }

    return JSON.parse(value)
  } catch (error) {
    console.error('Cache get error:', error)
    return null
  }
}

/**
 * è®¾ç½®ç¼“å­˜æ•°æ®
 */
export async function setCache(key, data, customCacheTime) {
  try {
    // éªŒè¯è¾“å…¥æ•°æ®
    if (data === undefined || data === null) {
      throw new Error('Cannot cache undefined or null data')
    }
    
    const jsonString = JSON.stringify(data)
    if (!jsonString || jsonString === 'undefined') {
      throw new Error('Failed to serialize data to JSON')
    }
    
    const dataBuffer = Buffer.from(jsonString, 'utf8')
    const dataSize = dataBuffer.length
    let finalValue = jsonString
    let compressionStats = null

    // æ™ºèƒ½å‹ç¼©ç­–ç•¥ï¼šä»…å¯¹å¤§äºé˜ˆå€¼çš„æ•°æ®è¿›è¡Œå‹ç¼©
    if (compressionAvailable && dataSize > COMPRESSION_THRESHOLD) {
      const compressionLevel = getDynamicCompressionLevel(dataSize)
      const startTime = Date.now()
      
      try {
        // ç¡®ä¿æ•°æ®ç¼“å†²åŒºæœ‰æ•ˆ
        if (!dataBuffer || dataBuffer.length === 0) {
          throw new Error('Invalid data buffer for compression')
        }
        
        const uint8Array = new Uint8Array(dataBuffer)
        if (!uint8Array || uint8Array.length === 0) {
          throw new Error('Failed to create Uint8Array from buffer')
        }
        
        const compressed = compressData(uint8Array, compressionLevel)
        const compressedSize = compressed.length
        const compressionTime = Date.now() - startTime
        const compressionRatio = (dataSize - compressedSize) / dataSize
        
        compressionStats = {
          originalSize: dataSize,
          compressedSize,
          compressionRatio,
          compressionTime,
          level: compressionLevel
        }
        
        // ä»…åœ¨å‹ç¼©æ•ˆæœæ˜¾è‘—æ—¶ä½¿ç”¨å‹ç¼©ï¼ˆèŠ‚çœç©ºé—´â‰¥15%ï¼‰
        if (compressionRatio >= MIN_COMPRESSION_RATIO) {
          finalValue = 'ZSTD:' + Buffer.from(compressed).toString('base64')
          console.log(`ğŸ—œï¸ Cache compressed: ${(dataSize/1024).toFixed(1)}KB â†’ ${(compressedSize/1024).toFixed(1)}KB (${(compressionRatio*100).toFixed(1)}% saved, level ${compressionLevel}, ${compressionTime}ms)`)
        } else {
          console.log(`ğŸ“¦ Cache not compressed: ratio ${(compressionRatio*100).toFixed(1)}% < ${(MIN_COMPRESSION_RATIO*100)}% threshold`)
        }
      } catch (compressionError) {
        console.warn('âš ï¸ Compression failed, storing uncompressed:', compressionError.message)
      }
    } else if (!compressionAvailable && dataSize > COMPRESSION_THRESHOLD) {
      console.log('ğŸ“¦ Large data detected but ZSTD codec not available, storing uncompressed')
    }

    const ttl = customCacheTime || cacheTime
    await redisClient.setex(key, ttl, finalValue)
    
    return compressionStats
  } catch (error) {
    console.error('Cache set error:', error)
    throw error
  }
}

/**
 * åˆ é™¤ç¼“å­˜
 */
export async function delCache(key) {
  try {
    return await redisClient.del(key)
  } catch (error) {
    console.error('Cache delete error:', error)
    return 0
  }
}

/**
 * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
 */
export async function getCacheStats(keyPattern = '*') {
  try {
    const keys = await redisClient.keys(keyPattern)
    if (keys.length === 0) {
      return { totalKeys: 0, totalSize: 0, compressedKeys: 0, uncompressedKeys: 0 }
    }

    // é‡‡æ ·å‰100ä¸ªé”®è¿›è¡Œç»Ÿè®¡
    const sampleKeys = keys.slice(0, 100)
    const values = await redisClient.mget(sampleKeys)
    
    let totalSize = 0
    let compressedKeys = 0
    let uncompressedKeys = 0
    
    values.forEach(value => {
      if (value) {
        totalSize += Buffer.byteLength(value, 'utf8')
        if (value.startsWith('ZSTD:')) {
          compressedKeys++
        } else {
          uncompressedKeys++
        }
      }
    })
    
    return {
      totalKeys: keys.length,
      sampledKeys: sampleKeys.length,
      totalSize: Math.round(totalSize / 1024), // KB
      compressedKeys,
      uncompressedKeys,
      compressionRatio: compressedKeys / (compressedKeys + uncompressedKeys)
    }
  } catch (error) {
    console.error('Cache stats error:', error)
    return { error: error.message }
  }
}

export default { getCache, setCache, delCache, getCacheStats }